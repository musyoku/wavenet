## WaveNet: A Generative Model for Raw Audio

- code for the [paper](http://arxiv.org/abs/1609.03499)
- [ã“ã®è¨˜äº‹](http://musyoku.github.io/2016/09/18/wavenet-a-generative-model-for-raw-audio/)ã§å®Ÿè£…ã—ãŸã‚³ãƒ¼ãƒ‰ã§ã™ã€‚

ã¾ã å®Œæˆã—ã¦ã„ã¾ã›ã‚“ãŒéŸ³å£°ã®ç”Ÿæˆã¯ã§ãã¾ã™ã€‚

#### Todo:
- [x] Generating audio
- [ ] Local conditioning
- [ ] Global conditioning

### Requirements

- Chainer 1.21
- scipy.io.wavfile

### Preprocessing

Donwsample your .wav to 16KHz / 8KHz to speed up convergence.

- [Aaudacity](http://www.audacityteam.org/)

### Create data directory

Add all .wav files to `/train_audio/wav`

### Training

`python train.py -w wav --lr 0.001`

We recommend to stop training if the error saturates and lower the learning rate and start training again.

e.g.

0.001 -> 0.0005 -> 0.00025 -> 0.00001

å­¦ç¿’ç‡ã®èª¿æ•´ã¯ã‚ã‚Šã¨ã‚·ãƒ“ã‚¢ã§ã™ã€‚

æ”¾ç½®ã—ã¦ãŠãå ´åˆã¯0.00001ä»¥ä¸‹ã®å€¤ã«è¨­å®šã—ã¾ã™ã€‚

### Generating audio

`python generate.py -s 5 --fast`

Passing `--fast` will generate audio faster than original WaveNet.

#### Listen to a sample generated by WaveNet

[ğŸ¶ music](https://drive.google.com/file/d/0ByQaxyG1S5JRWUZrQkpaMTJRNFk/view)

## Implementation

![figure](https://github.com/musyoku/musyoku.github.io/blob/master/images/post/2016-09-17/arch.png?raw=true)

![figure](https://github.com/musyoku/musyoku.github.io/blob/master/images/post/2016-09-17/block.png?raw=true)

![figure](https://github.com/musyoku/musyoku.github.io/blob/master/images/post/2016-09-17/actual_data.png?raw=true)

![figure](https://pbs.twimg.com/media/C4xfueRWIAAtrwJ.png)

[https://twitter.com/heiga_zen/status/832145314559750145](https://twitter.com/heiga_zen/status/832145314559750145)